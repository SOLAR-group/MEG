{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "This is a Python script that parses the output from replication study for cross-version (make sure the output folders are in the same directory as this file), extracting the MCC values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isfloat(value):\n",
    "  try:\n",
    "    float(value)\n",
    "    return True\n",
    "  except ValueError:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreementCols = ['SC', 'Bagging*MCC', 'Boosting*MCC', \n",
    " 'Stacking_by_DIV*MCC',  'Stacking_by_MCC*MCC', 'Stacking_by_PRECISION*MCC', 'Stacking_by_WAD*MCC', 'Bagging*PREC', 'Boosting*PREC', 'Stacking_by_DIV*PREC', 'Stacking_by_MCC*PREC', 'Stacking_by_PRECISION*PREC',  'Stacking_by_WAD*PREC', 'NB', 'J48', 'KNN', 'SMO']\n",
    "\n",
    "otherDivCols = ['Stacking_by_DIV*MCC', 'Stacking_by_WAD*MCC', 'Stacking_by_DIV*PREC', 'Stacking_by_WAD*PREC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv_mcc_values(div, experiment, projects):\n",
    "    mccs = defaultdict(list)      \n",
    "    \n",
    "    print(f'Diversity: {div}\\tVariant: {experiment}')\n",
    "    for p in projects:\n",
    "        print(f'Project: {p}')\n",
    "        for dirname, _, filenames in os.walk(f'./{div}/{experiment}'):\n",
    "            for filename in filenames:\n",
    "                path = os.path.join(dirname, filename)\n",
    "                split = path.split('/')\n",
    "                clf = split[len(split)-2]\n",
    "                project = split[len(split)-1]\n",
    "\n",
    "                if project != p: continue\n",
    "\n",
    "                # print(f'Classifier: {clf}')\n",
    "\n",
    "                if clf == 'Base':\n",
    "                    # parse base in a different way\n",
    "                    parseNext = False\n",
    "                    i = 0\n",
    "                    with open(path) as f:\n",
    "                        for line in f:\n",
    "                            line = line.rstrip()\n",
    "                            if len(line) == 0: continue\n",
    "                            if line == '============ OVERALL MCC STATS ==============':\n",
    "                                parseNext = True\n",
    "                            elif parseNext and isfloat(line):\n",
    "                                # parse mcc\n",
    "                                if i == 0:\n",
    "                                    mccs['SC'].append(float(line))\n",
    "                                if i == 1:\n",
    "                                    mccs['NB'].append(float(line))\n",
    "                                if i == 2:\n",
    "                                    mccs['J48'].append(float(line))\n",
    "                                if i == 3:\n",
    "                                    mccs['KNN'].append(float(line))  \n",
    "                                if i == 4:\n",
    "                                    mccs['SMO'].append(float(line))   \n",
    "                                parseNext = False\n",
    "                                i += 1\n",
    "                else:\n",
    "                    parseNext = False\n",
    "                    i = 0\n",
    "                    prevMeta = ''\n",
    "                    with open(path) as f:\n",
    "                        for line in f:\n",
    "                            line = line.rstrip()\n",
    "                            if len(line) == 0: continue\n",
    "                            if \"with meta\" in line:\n",
    "                                # get the meta classifier\n",
    "                                meta = line.split(':')[1].strip()\n",
    "                            elif line == '============ OVERALL MCC STATS ==============':\n",
    "                                parseNext = True\n",
    "                            elif parseNext and isfloat(line):\n",
    "                                # parse mcc\n",
    "                                if prevMeta == meta:\n",
    "                                    # same meta clf\n",
    "\n",
    "                                    # for bagging and boosting classifers output, output file always contains results for \n",
    "                                    # best classifier by MCC followed by best classifier by PRECISION as the logic for skipping\n",
    "                                    # was broken when the scripts ran. \n",
    "                                    mccs[clf+(\"*MCC\" if i==0 else \"*PREC\")].append('x')\n",
    "                                else:\n",
    "                                    mccs[clf+(\"*MCC\" if i==0 else \"*PREC\")].append(float(line))\n",
    "                                parseNext = False\n",
    "                                prevMeta = meta\n",
    "                                i += 1\n",
    "                    if i == 1:\n",
    "                        # this is only used for stacking classifiers\n",
    "                        # as the logic for skipping work if best classifier by MCC == best classifier by PRECISION was working\n",
    "                        # correctly, unlike bagging and boostingdef isfloat(value):\n",
    "                        mccs[clf+\"*PREC\"].append('x')\n",
    "\n",
    "    # create a pandas dataframe\n",
    "    df = pd.DataFrame(mccs, index=projects)\n",
    "    \n",
    "    # rearrange columns to match order in the sheet uploaded on GDrive\n",
    "    if div == 'DISAGREEMENT':\n",
    "        df = df[disagreementCols]\n",
    "    else:\n",
    "        df = df[otherDivCols]\n",
    "\n",
    "    df.to_csv(f'results/{div}/{experiment}.csv', encoding='utf-8', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Diversity: DISAGREEMENT\tVariant: firstLast\n",
      "Project: activemq\n",
      "Project: camel\n",
      "Project: derby\n",
      "Project: groovy\n",
      "Project: hbase\n",
      "Project: hive\n",
      "Project: jruby\n",
      "Project: lucene\n",
      "Project: wicket\n",
      "Diversity: DISAGREEMENT\tVariant: penultimate-last\n",
      "Project: activemq\n",
      "Project: camel\n",
      "Project: derby\n",
      "Project: groovy\n",
      "Project: hbase\n",
      "Project: hive\n",
      "Project: jruby\n",
      "Project: lucene\n",
      "Project: wicket\n",
      "Diversity: CORRELATION\tVariant: firstLast\n",
      "Project: activemq\n",
      "Project: camel\n",
      "Project: derby\n",
      "Project: groovy\n",
      "Project: hbase\n",
      "Project: hive\n",
      "Project: jruby\n",
      "Project: lucene\n",
      "Project: wicket\n",
      "Diversity: CORRELATION\tVariant: penultimate-last\n",
      "Project: activemq\n",
      "Project: camel\n",
      "Project: derby\n",
      "Project: groovy\n",
      "Project: hbase\n",
      "Project: hive\n",
      "Project: jruby\n",
      "Project: lucene\n",
      "Project: wicket\n",
      "Diversity: DOUBLE_FAULT\tVariant: firstLast\n",
      "Project: activemq\n",
      "Project: camel\n",
      "Project: derby\n",
      "Project: groovy\n",
      "Project: hbase\n",
      "Project: hive\n",
      "Project: jruby\n",
      "Project: lucene\n",
      "Project: wicket\n",
      "Diversity: DOUBLE_FAULT\tVariant: penultimate-last\n",
      "Project: activemq\n",
      "Project: camel\n",
      "Project: derby\n",
      "Project: groovy\n",
      "Project: hbase\n",
      "Project: hive\n",
      "Project: jruby\n",
      "Project: lucene\n",
      "Project: wicket\n",
      "Diversity: QSTATISTIC\tVariant: firstLast\n",
      "Project: activemq\n",
      "Project: derby\n",
      "Project: groovy\n",
      "Project: hbase\n",
      "Project: hive\n",
      "Project: jruby\n",
      "Project: lucene\n",
      "Project: wicket\n",
      "Diversity: QSTATISTIC\tVariant: penultimate-last\n",
      "Project: activemq\n",
      "Project: derby\n",
      "Project: groovy\n",
      "Project: hbase\n",
      "Project: hive\n",
      "Project: jruby\n",
      "Project: lucene\n",
      "Project: wicket\n"
     ]
    }
   ],
   "source": [
    "diversities = ['DISAGREEMENT', 'CORRELATION', 'DOUBLE_FAULT', 'QSTATISTIC']\n",
    "experiments = ['firstLast','penultimate-last']\n",
    "projects = ['activemq', 'camel', 'derby', 'groovy', 'hbase', 'hive', 'jruby', 'lucene', 'wicket']\n",
    "\n",
    "for div in diversities:\n",
    "    for experiment in experiments:\n",
    "        # temporarily remove camel-penultimate from QSTATISTIC as it is missing some data\n",
    "        if div == 'QSTATISTIC':\n",
    "            projects = list(filter(lambda p: p != 'camel', projects))\n",
    "        generate_csv_mcc_values(div, experiment, projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}